<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="聚类 # 基于对象的聚类(Objective based clustering) # K-means 聚类 # k-means 问题描述: 找到cpt1,cpt2,&mldr;.cpt, 使 $ min\sum_{i=1}^n m_{j \in 1 \cdots k} d^2(x^i,c_j) $ k-median 问题描述: 找到cpt1,cpt2,&mldr;.cpt, 使 $ min\sum_{i=1}^n m_{j \in 1 \cdots k} d(x^i,c_j) $ k-center 问题描述: 找到一个分类方式最小化最大半径 Lloyds method: 总是收敛的(目标函数单调递减,并且有下界, 该方法一定收敛) # 问题描述:
Input: 一组数据集 $ x^1, x^2, \cdots, x^n \in R^d$ Initialize: 1. 中心点 $c_1, c_2, \cdots, c_k \in R^d$ 2. 簇$C_1,C_2,\cdots,C_k$以随机方式聚合 Repeat:直到目标函数没有任何变化 1. for each j: $C_j \in {x \in S }$ where closest center is $c_j$ 2."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="/posts/machine_learning/ml_video12_aggregation/"><meta property="og:title" content="机器学习-视频学习系列12-聚类"><meta property="og:description" content="聚类 # 基于对象的聚类(Objective based clustering) # K-means 聚类 # k-means 问题描述: 找到cpt1,cpt2,….cpt, 使 $ min\sum_{i=1}^n m_{j \in 1 \cdots k} d^2(x^i,c_j) $ k-median 问题描述: 找到cpt1,cpt2,….cpt, 使 $ min\sum_{i=1}^n m_{j \in 1 \cdots k} d(x^i,c_j) $ k-center 问题描述: 找到一个分类方式最小化最大半径 Lloyds method: 总是收敛的(目标函数单调递减,并且有下界, 该方法一定收敛) # 问题描述:
Input: 一组数据集 $ x^1, x^2, \cdots, x^n \in R^d$ Initialize: 1. 中心点 $c_1, c_2, \cdots, c_k \in R^d$ 2. 簇$C_1,C_2,\cdots,C_k$以随机方式聚合 Repeat:直到目标函数没有任何变化 1. for each j: $C_j \in {x \in S }$ where closest center is $c_j$ 2."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-06-07T16:02:35+00:00"><meta property="article:modified_time" content="2019-06-07T16:02:35+00:00"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="聚类"><meta property="article:tag" content="视频"><title>机器学习-视频学习系列12-聚类 | </title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=canonical href=/posts/machine_learning/ml_video12_aggregation/><link rel=stylesheet href=/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css><script defer src=/fuse.min.js></script><script defer src=/en.search.min.8aa13e2f4b9fdd1fa1c269db82d4ba6bb2746e64391b4052adb11ab4309caef3.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>机器学习-视频学习系列12-聚类</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#聚类>聚类</a><ul><li><a href=#基于对象的聚类objective-based-clustering>基于对象的聚类(Objective based clustering)</a></li><li><a href=#层次聚类hierarchical-clustering>层次聚类(Hierarchical clustering)</a></li><li><a href=#k-means-代码分析及实现>K-means 代码分析及实现</a></li></ul></li></ul></nav></aside></header><article class="markdown book-post"><h1><a href=/posts/machine_learning/ml_video12_aggregation/>机器学习-视频学习系列12-聚类</a></h1><h5>June 7, 2019</h5><div><a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></div><div><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a>,
<a href=/tags/%E8%81%9A%E7%B1%BB/>聚类</a>,
<a href=/tags/%E8%A7%86%E9%A2%91/>视频</a></div><h2 id=聚类>聚类
<a class=anchor href=#%e8%81%9a%e7%b1%bb>#</a></h2><h3 id=基于对象的聚类objective-based-clustering>基于对象的聚类(Objective based clustering)
<a class=anchor href=#%e5%9f%ba%e4%ba%8e%e5%af%b9%e8%b1%a1%e7%9a%84%e8%81%9a%e7%b1%bbobjective-based-clustering>#</a></h3><h4 id=k-means-聚类>K-means 聚类
<a class=anchor href=#k-means-%e8%81%9a%e7%b1%bb>#</a></h4><ul><li>k-means 问题描述: 找到cpt1,cpt2,&mldr;.cpt, 使 $ min\sum_{i=1}^n m_{j \in 1 \cdots k} d^2(x^i,c_j) $</li><li>k-median 问题描述: 找到cpt1,cpt2,&mldr;.cpt, 使 $ min\sum_{i=1}^n m_{j \in 1 \cdots k} d(x^i,c_j) $</li><li>k-center 问题描述: 找到一个分类方式最小化最大半径</li></ul><h4 id=lloyds-method-总是收敛的目标函数单调递减并且有下界-该方法一定收敛>Lloyds method: 总是收敛的(目标函数单调递减,并且有下界, 该方法一定收敛)
<a class=anchor href=#lloyds-method-%e6%80%bb%e6%98%af%e6%94%b6%e6%95%9b%e7%9a%84%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0%e5%8d%95%e8%b0%83%e9%80%92%e5%87%8f%e5%b9%b6%e4%b8%94%e6%9c%89%e4%b8%8b%e7%95%8c-%e8%af%a5%e6%96%b9%e6%b3%95%e4%b8%80%e5%ae%9a%e6%94%b6%e6%95%9b>#</a></h4><p>问题描述:</p><blockquote><p>Input: 一组数据集 $ x^1, x^2, \cdots, x^n \in R^d$
Initialize:
1. 中心点 $c_1, c_2, \cdots, c_k \in R^d$
2. 簇$C_1,C_2,\cdots,C_k$以随机方式聚合
Repeat:直到目标函数没有任何变化
1. for each j: $C_j \in {x \in S }$ where closest center is $c_j$
2. for each j: $c_j \in avg(c_j)$</p></blockquote><ul><li>初始化很重要(决定了收敛的快慢和输出的质量), 常用的有三种:</li></ul><ol><li>随机挑选中心化点. performance 比较差. 随着k的增大, 效果指数级下降
对于k个高斯分布来说, 每个初始化的中心正好在一个不同的高斯分布的概率$\approx\frac {k!}{k^k}\approx\frac1{e^k}$</li><li>最远遍历(Furthest Point Heuristic)
先固定一个$c_j$,然后在后续每次取中心点的时候, 都评估距离已经选出来的点最远的点作为当前的中心点. 以此类推, 选出k个中心点. 解决了高斯分布的问题, 但是可能对噪声(outlier)特别敏感</li><li>K-means++ (效果好, 效率快): 基本思路$D^{\alpha}$抽样
理论上 K-means++ 会得到O(logk)的最优解.
如果$\alpha$=0, 就是随机抽样
如果$\alpha$=$\infin$, 就是最远点初始化
如果$\alpha$=2, k-means++</li></ol><ul><li><p>K-means++/Lloyd&rsquo;s 运行的时间复杂度
K-means++ 初始化: O(nkd) ,其中n是样本点个数,k是聚类个数, d是样本维度</p></li><li><p>如何选择k</p></li></ul><ol><li>交叉验证</li><li>Elbow&rsquo;s method. 找到不同k之间的损失函数下降最快的地方.</li><li>尝试层次聚类</li></ol><h3 id=层次聚类hierarchical-clustering>层次聚类(Hierarchical clustering)
<a class=anchor href=#%e5%b1%82%e6%ac%a1%e8%81%9a%e7%b1%bbhierarchical-clustering>#</a></h3><p>主要讲由下至上的层次聚类
1:34:16 to be continue</p><h3 id=k-means-代码分析及实现>K-means 代码分析及实现
<a class=anchor href=#k-means-%e4%bb%a3%e7%a0%81%e5%88%86%e6%9e%90%e5%8f%8a%e5%ae%9e%e7%8e%b0>#</a></h3></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#聚类>聚类</a><ul><li><a href=#基于对象的聚类objective-based-clustering>基于对象的聚类(Objective based clustering)</a></li><li><a href=#层次聚类hierarchical-clustering>层次聚类(Hierarchical clustering)</a></li><li><a href=#k-means-代码分析及实现>K-means 代码分析及实现</a></li></ul></li></ul></nav></div></aside></main></body></html>